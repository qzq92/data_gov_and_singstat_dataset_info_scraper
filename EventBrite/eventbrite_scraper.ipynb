{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EventBrite SG Events information scraper.\n",
    "This notebook is used for pulling and consolidating datasets found in EventBrite page https://www.eventbrite.sg/d/singapore--singapore/all-events/?page=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from typing import Tuple, Union\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the firefox profile options set to speed up loading process. Note: Do download and Install GeckoDriver in Selenium and set the PATH variable in sys variable to point to it in order to ensure that the FireFox Driver for Selenium can work. You may point it via a Service module of selenium' firefox service instead of using PATH variable as an alternative as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options=Options()\n",
    "firefox_option = webdriver.FirefoxProfile()\n",
    "firefox_option.set_preference(\"network.http.pipelining\", True)\n",
    "firefox_option.set_preference(\"network.http.proxy.pipelining\", True)\n",
    "firefox_option.set_preference(\"network.http.pipelining.maxrequests\", 8)\n",
    "firefox_option.set_preference(\"content.notify.interval\", 500000)\n",
    "firefox_option.set_preference(\"content.notify.ontimer\", True)\n",
    "firefox_option.set_preference(\"content.switch.threshold\", 250000)\n",
    "\n",
    "options.profile = firefox_option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main execution of info scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_venue_date_info(href:str, options: Options, multi_date:bool) -> Union[Tuple[str,str], Tuple[list,list]]:\n",
    "    \"\"\"Function which search for venue and date information from provided href link.\n",
    "\n",
    "    Args:\n",
    "        href (str): href link for webdriver to access to pull required info.\n",
    "        options (Options): Selenium webdriver options.\n",
    "\n",
    "    Returns:\n",
    "        Union[tuple[str,str], tuple[list,list]]: _description_\n",
    "    \"\"\"\n",
    "    service = Service(executable_path=r\"C:\\Program Files\\geckodriver.exe\")\n",
    "    new_driver = webdriver.Firefox(service=service, options=options)\n",
    "    new_driver.get(href)\n",
    "\n",
    "    alternative_date_xpath = \"//p[contains(text(), 'Date:')]\"\n",
    "    alternative_location_xpath = \"//p[contains(text(), 'Venue:') or contains(text(), 'Location:') or contains(text(), 'Address:') or contains(text(), 'Place:')]\"\n",
    "    location_xpath = \"//div[@class='location-info__address']\"\n",
    "    view_all_event_detail_xpath = \"//button[@data-testid='view-event-details-button']\"\n",
    "    #datetime_xpath = \"//*[@class='DateCard-module__root___28_4K']\"\n",
    "\n",
    "    try:\n",
    "        new_driver.find_element(by=By.XPATH, value=view_all_event_detail_xpath).click()\n",
    "        print(\"Found view all event details to click\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"No view all event details to click\")\n",
    "\n",
    "    if not multi_date:\n",
    "        datetime_xpath = \"//span[@class='date-info__full-datetime']\"\n",
    "        try:\n",
    "            datetime_info = new_driver.find_element(by=By.XPATH, value=datetime_xpath).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Cant find datetime element. Setting to None.\")\n",
    "            datetime_info = \"\"\n",
    "\n",
    "        # Use alternative datexpath\n",
    "        if datetime_info == \"\":\n",
    "            try:\n",
    "                datetime_info = new_driver.find_element(by=By.XPATH, value=alternative_date_xpath).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Cant find datetime element using alternative xpath. Setting to None.\")\n",
    "                datetime_info = \"\"\n",
    "        try:\n",
    "            location_info = new_driver.find_element(by=By.XPATH, value=location_xpath).text\n",
    "            location_info = location_info.split(\"\\n\")[0]\n",
    "        except NoSuchElementException:\n",
    "            print(\"Cant find location element. Setting to None.\")\n",
    "            location_info = \"\"\n",
    "\n",
    "                # Use alternative datexpath\n",
    "        if location_info == \"\":\n",
    "            try:\n",
    "                location_info = new_driver.find_element(by=By.XPATH, value=alternative_location_xpath).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Cant find location element using alternative xpath. Setting to None.\")\n",
    "                location_info = \"\"\n",
    "\n",
    "        new_driver.quit()\n",
    "        return datetime_info, location_info\n",
    "    # Return a list of date/location when multiple datetimes are found\n",
    "    else:\n",
    "        datetime_list_xpath = \"//li[@class='child-event-dates-item']\"\n",
    "        datetime_info_list = new_driver.find_elements(by=By.XPATH, value=datetime_list_xpath)\n",
    "\n",
    "        datetime_info_list = []\n",
    "        location_info_list = []\n",
    "        for datetime_info in datetime_info_list:\n",
    "            datetime_info.click()\n",
    "            try:\n",
    "                datetime_info = new_driver.find_element(by=By.XPATH, value=datetime_xpath).text\n",
    "                #print(f\"Datetime info: {datetime_info}\")\n",
    "            except NoSuchElementException:\n",
    "                #print(\"Cant find datetime element. Setting to None.\")\n",
    "                datetime_info = \"\"\n",
    "            try:\n",
    "                location_info = new_driver.find_element(by=By.XPATH, value=location_xpath).text\n",
    "                location_info = location_info.split(\"\\n\")[0]\n",
    "            except NoSuchElementException:\n",
    "                #print(\"Cant find location element. Setting to None.\")\n",
    "                location_info = \"\"\n",
    "            # Append information\n",
    "            datetime_info_list.append(datetime_info)\n",
    "            location_info_list.append(location_info)\n",
    "        # Quit driver after completion\n",
    "        new_driver.quit()\n",
    "        return datetime_info_list, location_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1\n",
      "\n",
      "No view all event details to click\n",
      "Cant find datetime element. Setting to None.\n",
      "Cant find datetime element using alternative xpath. Setting to None.\n",
      "\n",
      "No view all event details to click\n",
      "Cant find datetime element. Setting to None.\n",
      "Cant find datetime element using alternative xpath. Setting to None.\n",
      "\n",
      "\n",
      "Found view all event details to click\n",
      "\n",
      "\n",
      "No view all event details to click\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "No view all event details to click\n",
      "\n",
      "No view all event details to click\n",
      "\n",
      "\n",
      "\n",
      "No view all event details to click\n",
      "\n",
      "No view all event details to click\n",
      "Cant find datetime element. Setting to None.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Saving to csv file\n",
      "Processing page 2\n",
      "No view all event details to click\n",
      "\n",
      "No view all event details to click\n",
      "\n",
      "\n",
      "No view all event details to click\n"
     ]
    }
   ],
   "source": [
    "#CFG\n",
    "URL = \"https://www.eventbrite.sg/d/singapore--singapore/all-events/?page=1\"\n",
    "service = Service(executable_path=r\"C:\\Program Files\\geckodriver.exe\")\n",
    "driver = webdriver.Firefox(service=service, options=options)\n",
    "driver.get(URL)\n",
    "\n",
    "# pagination xpath\n",
    "paginate_xpath= \"//ul[@class='eds-pagination__navigation-group']/li[contains(@class, eds-pagination__navigation-minimal)][2]\"\n",
    "\n",
    "# Webpage wait for required paginate stuff to load\n",
    "WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, paginate_xpath)))\n",
    "\n",
    "try: \n",
    "    total_page_div =  driver.find_element(by=By.XPATH, value=paginate_xpath).text\n",
    "    # Get the total page number from the html text in the format: 'of X'\n",
    "    total_page = int(total_page_div.split(\" \")[-1])\n",
    "except NoSuchElementException:\n",
    "    print(\"Unable to find pagination information. Only current page will be scraped.\")\n",
    "    total_page = 1\n",
    "\n",
    "# List to track extracted events\n",
    "event_tracking_list = []\n",
    "\n",
    "for page in np.arange(1, total_page + 1):\n",
    "    page_url = f\"https://www.eventbrite.sg/d/singapore--singapore/all-events/?page={page}\"\n",
    "    print(f\"Processing page {page}\")\n",
    "    #Switch page\n",
    "    driver.get(page_url)\n",
    "    event_xpath = \"//div[contains(@class, 'event-card__horizontal')]/section[@class='event-card-details']\"\n",
    "    events_div_list = driver.find_elements(by=By.XPATH, value=event_xpath)\n",
    "    for event in events_div_list:\n",
    "        event_title_xpath = \"./div/a\"\n",
    "        try:\n",
    "            event_title = event.find_element(by=By.XPATH, value=event_title_xpath).text\n",
    "\n",
    "            event_href= event.find_element(by=By.XPATH, value=event_title_xpath).get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            print(\"Unable to get event title. Skipping current event\")\n",
    "            continue\n",
    "        \n",
    "        # Skip cases for Malaysia related event (hardcoded)\n",
    "        if \"in Johor\" in event_title or \"Pasir Gudang\" in event_title:\n",
    "            print(\"Detected event name hosted in Johor, skipping this event from inclusion\")\n",
    "            continue\n",
    "        # Event date/location information\n",
    "        event_date_location_xpath = \"./div/p\"\n",
    "        event_date_location_ele_list = event.find_elements(by=By.XPATH, value=event_date_location_xpath)\n",
    "\n",
    "        # When both date and venue info are available\n",
    "        if len(event_date_location_ele_list) == 2:\n",
    "\n",
    "            event_date = event_date_location_ele_list[0].text\n",
    "            event_location = event_date_location_ele_list[1].text\n",
    "\n",
    "            # Get actual date info from href page as eventbrite does not list actual date on the page itself if the event occurs within few days of the date which data is scraped. (e.g at thurs, XX:XX when viewing page for scraping is done on wed or before).\n",
    "            if \" at \" in event_date :\n",
    "                event_date, event_location = find_venue_date_info(\n",
    "                href=event_href,\n",
    "                options=options,\n",
    "                multi_date=False\n",
    "            )\n",
    "            # When there is more dates to it as indicated by + X more in the text\n",
    "            elif \" +\" in event_date and \" more\" in event_date:\n",
    "                print(f\"Multiple dates found for {event_title}\")\n",
    "                event_date, event_location = find_venue_date_info(\n",
    "                href=event_href,\n",
    "                options=options,\n",
    "                multi_date=True\n",
    "            )\n",
    "        # When date or venue info is lacking or abundance of info\n",
    "        else:\n",
    "            event_date, event_location = find_venue_date_info(\n",
    "                href=event_href,\n",
    "                options=options,\n",
    "                multi_date=False\n",
    "            )\n",
    "        \n",
    "        # For multiple dates case. loop through and consolidate the dates\n",
    "        if isinstance(event_date, list) and isinstance(event_location, list):\n",
    "            for date,location in zip(event_date, event_location):\n",
    "                event_metadata_list = [event_title, date, location, event_href]\n",
    "                print(event_metadata_list)\n",
    "                event_tracking_list.append(event_metadata_list)\n",
    "        else:\n",
    "            event_metadata_list = [event_title, event_date, event_location, event_href]\n",
    "            #print(event_metadata_list)\n",
    "            event_tracking_list.append(event_metadata_list)\n",
    "        print()\n",
    "\n",
    "    # Due to large number of page to be processed, we will always save each page event as a file. Should anything go wrong, we can identify the page which needs to be rescraped onwards.\n",
    "    print(\"Saving to csv file\")\n",
    "    df = pd.DataFrame(event_tracking_list, columns=[\"Event Title\", \"Date\", \"Location\", \"URL\"])\n",
    "    \n",
    "    # Drop duplicates for cases with same date/location/url\n",
    "    df.drop_duplicates(subset=[\"Date\", \"Location\", \"URL\"], inplace=True, keep=\"last\")\n",
    "    df.dropna(subset=[\"Date\", \"Location\", \"URL\"], inplace=True)\n",
    "    datetime_now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    file_name_date = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "    df[\"Date_of_check\"] = datetime_now\n",
    "\n",
    "    dataset_filename = f\"EventBrite_dataset_{file_name_date}_page_{page}.csv\"\n",
    "    df.to_csv(dataset_filename, index=False, encoding='utf-8')\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
